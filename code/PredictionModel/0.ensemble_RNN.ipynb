{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder, ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_sequence(folder, target_size=(224, 224), sequence_length=224):\n",
    "    sequences_list = []\n",
    "    labels = []\n",
    "    for label in [\"HC\", \"PD\"]:\n",
    "        label_path = os.path.join(folder, label)\n",
    "        for image_name in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_name)\n",
    "            img = load_img(image_path, color_mode=\"grayscale\", target_size=target_size)\n",
    "            image_array = img_to_array(img)\n",
    "            img_array = image_array / 255.0 #normalize\n",
    "            sequences = img_array.reshape((sequence_length, -1))\n",
    "            sequences_list.append(sequences)\n",
    "            labels.append(label)\n",
    "            \n",
    "    sequences = np.array(sequences_list)\n",
    "    labels = np.array(labels)\n",
    "    return sequences, labels\n",
    "\n",
    "drawings_sequences, drawings_labels = images_to_sequence(\"drawings\")\n",
    "speech_sequences, speech_labels = images_to_sequence(\"speech\")\n",
    "\n",
    "#encode labels to numerical\n",
    "label_encoder = LabelEncoder()\n",
    "drawings_labels_encoded = label_encoder.fit_transform(drawings_labels)\n",
    "speech_labels_encoded = label_encoder.fit_transform(speech_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(input_shape, num_units=128):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(num_units, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(num_units))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# RNN models\n",
    "drawings_rnn = create_rnn_model(input_shape=drawings_sequences[0].shape)\n",
    "speech_rnn = create_rnn_model(input_shape=speech_sequences[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (2295855561.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    epochs=10)\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "drawings_label_oh= to_categorical(drawings_labels_encoded)\n",
    "drawings_rnn.fit(drawings_sequences, drawings_label_oh, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "speech_label_oh = to_categorical(speech_labels_encoded)\n",
    "speech_rnn.fit(speech_sequences, speech_label_oh, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "drawings_rnn.save('drawings_model.h5')\n",
    "speech_rnn.save('speech_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
