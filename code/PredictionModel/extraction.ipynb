{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "# OSError: cannot load library 'libsndfile.dll': error 0x7e\n",
    "# workaround:\n",
    "    # pip uninstall soundfile\n",
    "    # pip install soundfile\n",
    "import soundfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mono(data):\n",
    "    \"\"\"\n",
    "    Convert signal to mono\n",
    "    \"\"\"\n",
    "\n",
    "    if data.ndim != 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeatureExtraction():\n",
    "    def __init__(self, audio_name, sr, data: np.ndarray, save_path, frame_size=25, frame_shift=10):\n",
    "        self.audio_name = audio_name\n",
    "        self.sr = sr\n",
    "        self.data = data\n",
    "        self.save_path = save_path\n",
    "        self.total_samples = self.data.size\n",
    "        self.frame_size = frame_size\n",
    "        self.frame_shift = frame_shift\n",
    "        self.frame_size_samples = int(self.sr*(self.frame_size/1000))\n",
    "        self.frame_shift_samples = int(self.sr*(self.frame_shift/1000))\n",
    "        self.total_frames = (self.total_samples - self.frame_size_samples) // self.frame_shift_samples + 1 \n",
    "        self.fft_size = 1\n",
    "        while self.fft_size < self.frame_size_samples:\n",
    "            self.fft_size *= 2\n",
    "        self.spectrum_dims = int(self.fft_size / 2 + 1)\n",
    "        \n",
    "    def spectrum(self, frame):\n",
    "        \"\"\"\n",
    "        Computes magnitude spectrum of the given audio signal frame.\n",
    "\n",
    "        Args:\n",
    "            frame: frame of the audio signal, ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        # apply window to reduce the noise at the edge of each frame\n",
    "        frame = frame*np.hamming(self.frame_size_samples)\n",
    "\n",
    "        # compute the spectrum with FFT\n",
    "        spectrum = np.fft.fft(frame, n=self.fft_size)\n",
    "        abs_spectrum = np.abs(spectrum)\n",
    "\n",
    "        # take log of magnitude spectrum\n",
    "        magnitude_spec = np.log(abs_spectrum + 1e-7)\n",
    "\n",
    "        # magnitude spectrum is symmetry, thus second half is redundant \n",
    "        magnitude_spec = magnitude_spec[:np.int32(self.fft_size/2 + 1)]\n",
    " \n",
    "        return magnitude_spec\n",
    "    \n",
    "    def spectrogram(self, plot=False):\n",
    "        \"\"\"\n",
    "        Computes spectrogram of the given audio signal.\n",
    "    \n",
    "        Args:\n",
    "            plot: if visualize spectrogram or not, bool\n",
    "\n",
    "        Return:\n",
    "            spectrogram: spectrogram of the provided audio, ndarray\n",
    "        \"\"\"\n",
    "\n",
    "        # initialize a spectrogram array\n",
    "        spectrogram = np.zeros((self.total_frames, self.spectrum_dims))\n",
    "    \n",
    "        # compute spectrogram\n",
    "        for i in range(0, self.total_frames):\n",
    "            start = i*self.frame_shift_samples\n",
    "            frame = self.data[start : start + self.frame_size_samples].copy()\n",
    "        \n",
    "            # compute magnitude spectrum\n",
    "            magnitude_spec = self.spectrum(frame)\n",
    "\n",
    "            # store magnitude spectrum to the spectrogram array\n",
    "            spectrogram[i, : ] = magnitude_spec\n",
    "\n",
    "        if plot:\n",
    "            plt.imshow(spectrogram.T[-1::-1, :], aspect=\"auto\", extent=[0, self.total_samples/self.sr, 0, self.sr/2])\n",
    "            plt.xlabel(\"Time\")\n",
    "            plt.ylabel(\"Frequencies\")\n",
    "            plt.title(\"Mel-Spectrogram\")\n",
    "            plt.savefig(os.path.join(self.save_path, self.audio_name + \".png\"))\n",
    "\n",
    "        print(f\"The dimention of the spectrogram: {spectrogram.shape}\")\n",
    "\n",
    "        return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.dirname(__file__)\n",
    "root = os.path.dirname(os.path.dirname(file_path))\n",
    "audio_path = os.path.join(root, \"Audio/\") # Path to the audio folder\n",
    "save_path = os.path.join(root, \"Speech/\") # Path to the speech folder\n",
    "audios = glob.glob(audio_path + \"*.wav\") # List of audio files\n",
    "\n",
    "for audio in audios:\n",
    "    audio_name = os.path.splitext(os.path.basename(audio))[0] # Gets the audio file's name\n",
    "    data, sr = librosa.load(audio, sr=None) # Load an audio file as a floating point time series\n",
    "    data = convert_to_mono(data) # Converts the loaded audio file to mono if it is in stereo\n",
    "    \n",
    "    feature_extractor = AudioFeatureExtraction(audio_name, sr, data, save_path)\n",
    "    feature_extractor.spectrogram(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
