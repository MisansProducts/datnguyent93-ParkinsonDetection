{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract mel-spectrogram from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, TimeDistributed, LSTM, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find graphic specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dir_path):\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = ['PD', 'HC']\n",
    "    for label in labels:\n",
    "        path = os.path.join(dir_path, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = img_to_array(load_img(os.path.join(path, img), target_size=(640, 480)))  # Convert image to array\n",
    "                X.append(preprocess_input(img_arr))  # Preprocess the image using VGG16's preprocess_input method\n",
    "                y.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    try:\n",
    "        return np.array(X), np.array(y)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to create numpy arrays: {e}')\n",
    "        return None, None\n",
    "X, y = load_data('./plots/')\n",
    "# one-hot encoding\n",
    "y = to_categorical(y)\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ResNet model\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(640, 480, 3))\n",
    "\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 20, 15, 2048)      23587712  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 614400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               314573312 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 338162050 (1.26 GB)\n",
      "Trainable params: 314574338 (1.17 GB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 33s 6s/step - loss: 166.7330 - accuracy: 0.5312 - precision: 0.5312 - recall: 0.5312 - val_loss: 70.8771 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 0.6250\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 28.7213 - accuracy: 0.8687 - precision: 0.8687 - recall: 0.8687 - val_loss: 45.5213 - val_accuracy: 0.7750 - val_precision: 0.7750 - val_recall: 0.7750\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 3.2766 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9812 - val_loss: 13.1313 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 31s 6s/step - loss: 2.1087 - accuracy: 0.9812 - precision: 0.9812 - recall: 0.9812 - val_loss: 11.1337 - val_accuracy: 0.9000 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 11.0337 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 13.4431 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 16.4978 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 18.4215 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 19.6257 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.0000e+00 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 20.3744 - val_accuracy: 0.9250 - val_precision: 0.9250 - val_recall: 0.9250\n",
      "Loss: 20.37\n",
      "Accuracy: 92.50%\n",
      "Precision: 92.50%\n",
      "Recall: 92.50%\n"
     ]
    }
   ],
   "source": [
    "# Add new layers\n",
    "model = Sequential()\n",
    "model.add(resnet_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))  \n",
    "\n",
    "# Use the Adam optimizer with a specified learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.summary()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', Precision(), Recall()])\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "                    epochs=10, batch_size=32)\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Loss: %.2f' % loss)\n",
    "print('Accuracy: %.2f%%' % (accuracy * 100))\n",
    "print('Precision: %.2f%%' % (precision * 100))\n",
    "print('Recall: %.2f%%' % (recall * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m# Plot training & validation accuracy values\u001b[39;00m\n\u001b[0;32m     13\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m14\u001b[39m,\u001b[39m6\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], linewidth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     15\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m], linewidth\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m     16\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mResNes-CNN Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1400x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "# Change global font to Times New Roman\n",
    "font_dirs = ['/usr/share/fonts/truetype/msttcorefonts/', ]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "# font_list = font_manager.createFontList(font_files)\n",
    "# font_manager.fontManager.ttflist.extend(font_list)\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 37})\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(history.history['accuracy'], linewidth=5)\n",
    "plt.plot(history.history['val_accuracy'], linewidth=5)\n",
    "plt.title('ResNet-CNN Accuracy')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(history.history['loss'], linewidth=5)\n",
    "plt.plot(history.history['val_loss'], linewidth=5)\n",
    "plt.title('ResNet-CNN Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation precision values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(history.history['precision'])\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Model Precision')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation recall values\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(history.history['recall'])\n",
    "plt.plot(history.history['val_recall'])\n",
    "plt.title('Model Recall')\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
