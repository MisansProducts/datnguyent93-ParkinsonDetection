{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, LSTM, Dense, Reshape\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input shape\n",
    "input_shape = (256, 256, 3)  # Handwriting drawings specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def images_to_sequence(folder, target_size=(224, 224), sequence_length=224):\n",
    "#     sequences_list = []\n",
    "#     labels = []\n",
    "#     for label in [\"HC\", \"PD\"]:\n",
    "#         label_path = os.path.join(folder, label)\n",
    "#         for image_name in os.listdir(label_path):\n",
    "#             image_path = os.path.join(label_path, image_name)\n",
    "#             img = load_img(image_path, color_mode=\"grayscale\", target_size=target_size)\n",
    "#             image_array = img_to_array(img)\n",
    "#             img_array = image_array / 255.0 #normalize\n",
    "#             sequences = img_array.reshape((sequence_length, -1))\n",
    "#             sequences_list.append(sequences)\n",
    "#             labels.append(label)\n",
    "            \n",
    "#     sequences = np.array(sequences_list)\n",
    "#     labels = np.array(labels)\n",
    "#     return sequences, labels\n",
    "\n",
    "# drawings_sequences, drawings_labels = images_to_sequence(\"drawings\")\n",
    "# speech_sequences, speech_labels = images_to_sequence(\"speech\")\n",
    "\n",
    "# #encode labels to numerical\n",
    "# label_encoder = LabelEncoder()\n",
    "# drawings_labels_encoded = label_encoder.fit_transform(drawings_labels)\n",
    "# speech_labels_encoded = label_encoder.fit_transform(speech_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 697 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 173 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set up data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    './drawings/',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    './drawings/',\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 127, 127, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 127, 4064)         0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 127, 128)          2146816   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2197313 (8.38 MB)\n",
      "Trainable params: 2197249 (8.38 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_handwriting_model(input_shape):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    conv1 = Conv2D(32, kernel_size=(3,3), activation='relu')(input_layer)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    norm1 = BatchNormalization()(pool1)\n",
    "\n",
    "    # You can add more convolutional layers if needed\n",
    "\n",
    "    # LSTM layers expect sequential input. Since we're dealing with images, we will treat each row of pixels as a sequence.\n",
    "    # Therefore, we will flatten the 2D image into a series of 1D sequences.\n",
    "    flattened = Flatten()(norm1)\n",
    "    reshaped = Reshape((127, 127 * 32))(norm1)  # Change the dimensions according to your model's output\n",
    "    \n",
    "    # LSTM layers\n",
    "    lstm1 = LSTM(128, return_sequences=True)(reshaped)\n",
    "    lstm2 = LSTM(64)(lstm1)\n",
    "\n",
    "    # Output layer with a single neuron and sigmoid activation function for binary classification\n",
    "    output = Dense(1, activation='sigmoid')(lstm2)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model_handwriting = create_handwriting_model(input_shape)\n",
    "model_handwriting.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 24s 1s/step - loss: 0.3869 - accuracy: 0.8551 - val_loss: 0.3546 - val_accuracy: 0.8902\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 18s 800ms/step - loss: 0.3550 - accuracy: 0.8881 - val_loss: 0.3451 - val_accuracy: 0.8902\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 19s 873ms/step - loss: 0.3411 - accuracy: 0.8881 - val_loss: 0.3397 - val_accuracy: 0.8902\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 20s 901ms/step - loss: 0.3394 - accuracy: 0.8881 - val_loss: 0.3412 - val_accuracy: 0.8902\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 19s 883ms/step - loss: 0.3291 - accuracy: 0.8910 - val_loss: 0.3334 - val_accuracy: 0.8902\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 21s 965ms/step - loss: 0.3267 - accuracy: 0.8924 - val_loss: 0.3646 - val_accuracy: 0.8902\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 21s 964ms/step - loss: 0.3249 - accuracy: 0.8881 - val_loss: 0.3432 - val_accuracy: 0.8902\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 20s 908ms/step - loss: 0.3080 - accuracy: 0.8967 - val_loss: 0.3288 - val_accuracy: 0.8902\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 19s 889ms/step - loss: 0.2890 - accuracy: 0.9053 - val_loss: 0.3255 - val_accuracy: 0.8902\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 20s 919ms/step - loss: 0.2542 - accuracy: 0.9197 - val_loss: 0.5584 - val_accuracy: 0.6301\n"
     ]
    }
   ],
   "source": [
    "history_handwriting = model_handwriting.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 306ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [173, 160]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\datng\\iCloudDrive\\0. College\\0.Machine Learning Projects\\ParkinsonDetection\\ParkinsonDetection\\code\\PredictionModel\\drawingRNN.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/drawingRNN.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m true_classes \u001b[39m=\u001b[39m validation_generator\u001b[39m.\u001b[39mclasses\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/drawingRNN.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Generate a classification report\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/drawingRNN.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m report \u001b[39m=\u001b[39m classification_report(true_classes, predicted_classes, target_names\u001b[39m=\u001b[39;49mvalidation_generator\u001b[39m.\u001b[39;49mclass_indices\u001b[39m.\u001b[39;49mkeys())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/drawingRNN.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(report)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/drawingRNN.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Generate a confusion matrix\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:2545\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2410\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   2411\u001b[0m     {\n\u001b[0;32m   2412\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2436\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2437\u001b[0m ):\n\u001b[0;32m   2438\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2439\u001b[0m \n\u001b[0;32m   2440\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2543\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2545\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2547\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2548\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\datng\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [173, 160]"
     ]
    }
   ],
   "source": [
    "model_handwriting.save('handwriting_model.h5')\n",
    "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
    "# Predict the classes with the model\n",
    "validation_generator.reset()  # Ensure the generator is reset before making predictions\n",
    "predictions = model_handwriting.predict(validation_generator, steps=validation_steps, verbose=1)\n",
    "# Get the most probable class (since we are using a binary classifier with sigmoid activation, a threshold of 0.5 is used)\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\").flatten()  # Flatten to make it a 1D array\n",
    "# Get the true labels\n",
    "true_classes = validation_generator.classes[:validation_steps * validation_generator.batch_size]\n",
    "\n",
    "assert len(predicted_classes) == len(true_classes), \"Mismatch between predicted and true labels\"\n",
    "# Generate a classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=validation_generator.class_indices.keys())\n",
    "print(report)\n",
    "\n",
    "# Generate a confusion matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
