{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_data_from_folder(folder_path):\n",
    "#     images = []\n",
    "#     labels = []\n",
    "#     for label in [\"HC\", \"PD\"]:\n",
    "#         label_path = f\"{folder_path}/{label}\"\n",
    "#         for image_path in os.listdir(label_path):\n",
    "#             full_path = f\"{label_path}/{image_path}\"\n",
    "#             try:\n",
    "#                 img = imread(full_path)\n",
    "#                 # Convert all images to grayscale\n",
    "#                 if len(img.shape) == 3:\n",
    "#                     img = np.mean(img, axis=-1)\n",
    "#                 img = resize(img, (256, 256)).flatten()  # resize and flatten the image\n",
    "#                 images.append(img)\n",
    "#                 labels.append(label)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing image: {full_path}\")\n",
    "#                 print(f\"Error details: {e}\")\n",
    "#                 continue\n",
    "\n",
    "#     # Debugging step\n",
    "#     image_shapes = [img.shape for img in images]\n",
    "#     unique_shapes = set(image_shapes)\n",
    "#     print(f\"Unique image shapes encountered: {unique_shapes}\")\n",
    "\n",
    "#     return np.array(images), np.array(labels)\n",
    "\n",
    "# # Load data\n",
    "# drawings_X, drawings_y = load_data_from_folder(\"drawings\")\n",
    "# speech_X, speech_y = load_data_from_folder(\"speech\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/135 [=========================>....] - ETA: 8s"
     ]
    }
   ],
   "source": [
    "def prepare_images(image_paths, target_size=(224, 224)):\n",
    "    images = [img_to_array(load_img(img_path, target_size=target_size)) for img_path in image_paths]\n",
    "    return preprocess_input(np.array(images))\n",
    "\n",
    "drawing_paths = glob.glob(\"./drawings/**/**/*.png\", recursive=True)\n",
    "speech_paths = glob.glob(\"./speech/**/**/*.png\", recursive=True)\n",
    "\n",
    "drawings_X_resized = prepare_images(drawing_paths)\n",
    "speech_X_resized = prepare_images(speech_paths)\n",
    "\n",
    "# Load the ResNet50 model with weights pre-trained on ImageNet without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "\n",
    "drawings_features = base_model.predict(drawings_X_resized)\n",
    "speech_features = base_model.predict(speech_X_resized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance for Drawings:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       0.75      0.93      0.83       267\n",
      "          PD       0.81      0.50      0.62       165\n",
      "\n",
      "    accuracy                           0.76       432\n",
      "   macro avg       0.78      0.71      0.72       432\n",
      "weighted avg       0.77      0.76      0.75       432\n",
      "\n",
      "\n",
      "Performance for Speech:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          HC       1.00      0.94      0.97        17\n",
      "          PD       0.96      1.00      0.98        24\n",
      "\n",
      "    accuracy                           0.98        41\n",
      "   macro avg       0.98      0.97      0.97        41\n",
      "weighted avg       0.98      0.98      0.98        41\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # Assuming 2 classes: HC and PD\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape features to fit into the CNN\n",
    "drawings_features_reshaped = drawings_features.reshape(drawings_features.shape[0], 1, 1, drawings_features.shape[1])\n",
    "speech_features_reshaped = speech_features.reshape(speech_features.shape[0], 1, 1, speech_features.shape[1])\n",
    "\n",
    "# Train the CNN for drawings data\n",
    "drawings_model = create_cnn((1, 1, 2048))  # 2048 features from ResNet50 with pooling='avg'\n",
    "drawings_model.fit(drawings_features_reshaped, drawings_y, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Train the CNN for speech data\n",
    "speech_model = create_cnn((1, 1, 2048))\n",
    "speech_model.fit(speech_features_reshaped, speech_y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate, ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\datng\\iCloudDrive\\0. College\\0.Machine Learning Projects\\ParkinsonDetection\\ParkinsonDetection\\code\\PredictionModel\\0.ensemble.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/0.ensemble.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf_drawings\u001b[39m.\u001b[39;49msave(\u001b[39m'\u001b[39m\u001b[39mdrawings_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/datng/iCloudDrive/0.%20College/0.Machine%20Learning%20Projects/ParkinsonDetection/ParkinsonDetection/code/PredictionModel/0.ensemble.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m clf_speech\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mspeech_model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "drawings_model.save('drawings_model.h5')\n",
    "speech_model.save('speech_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
